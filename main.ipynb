{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best arm is 4 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### Hyper parameters ####\n",
    "\n",
    "num_arms = 5\n",
    "num_agents = 5\n",
    "max_epochs = 1000\n",
    "epsilon = 5\n",
    "influence_weight = 0.5\n",
    "device =  torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "##########################\n",
    "\n",
    "\n",
    "### Initialization ###\n",
    "\n",
    "arm_performance = torch.rand(num_arms, 2, device=device)\n",
    "history = torch.zeros(1, num_agents, num_arms, device=device)\n",
    "adjacency_matrix = torch.rand(num_agents, num_agents, device=device)\n",
    "######################\n",
    "\n",
    "best_arm = torch.argmax(arm_performance[:, 0])\n",
    "print(f\"Best arm is {best_arm+1} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_estimate = history.sum(dim=0) / (history.sum(dim=0).sum(dim=1).unsqueeze(1) + 1)\n",
    "performance_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_runs = 100\n",
    "\n",
    "averaged_history = torch.zeros( num_agents, num_arms, device=device, requires_grad=False)\n",
    "\n",
    "adjacency_matrix = torch.clamp(adjacency_matrix, min=0, max=1)\n",
    "\n",
    "\n",
    "for run in range(0, averaging_runs):     \n",
    "\n",
    "    history = torch.zeros(1, num_agents, num_arms, device=device)   \n",
    "    for epoch in range(1, max_epochs):\n",
    "\n",
    "            performance_estimate = history.sum(dim=0) / (history.sum(dim=0).sum(dim=1).unsqueeze(1) + 1)\n",
    "            choice = torch.argmax(performance_estimate + torch.sqrt(np.log(epoch)/(1+history.bool().sum(dim=0).int())) + influence_weight * adjacency_matrix.softmax(dim=0) @ performance_estimate, dim=1)\n",
    "            \n",
    "            rewards = torch.normal(mean=arm_performance[choice, 0], std=torch.abs(arm_performance[choice, 1]))\n",
    "\n",
    "\n",
    "            current_history  = torch.zeros(num_agents, num_arms, device=device)\n",
    "\n",
    "            for i in range(num_agents):\n",
    "                for j in range(num_arms):\n",
    "                    if j == choice[i]:\n",
    "                        current_history[i, j] = rewards[i]\n",
    "\n",
    "\n",
    "            history = torch.cat((history, current_history.unsqueeze(0)), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "    history = history.bool().sum(dim=0).float()\n",
    "    averaged_history += history\n",
    "\n",
    "averaged_history /= averaging_runs\n",
    "\n",
    "\n",
    "print(averaged_history)\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_true = history\n",
    "average_history_true = averaged_history\n",
    "adjacency_matrix_true = adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_agents):\n\u001b[1;32m     32\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_arms):\n\u001b[0;32m---> 33\u001b[0m         \u001b[39mif\u001b[39;00m j \u001b[39m==\u001b[39m choice[i]:\n\u001b[1;32m     34\u001b[0m             current_history[i, j] \u001b[39m=\u001b[39m rewards[i]\n\u001b[1;32m     37\u001b[0m history \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((history, current_history\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epochs = 1000\n",
    "\n",
    "\n",
    "adjacency_matrix = torch.rand(num_agents, num_agents, device=device, requires_grad=True)\n",
    "\n",
    "averaging_runs = 100\n",
    "\n",
    "optimizer = torch.optim.Adam([adjacency_matrix], lr=10)\n",
    "\n",
    "for train_epoch in range(train_epochs):\n",
    "\n",
    "    \n",
    "\n",
    "    adjacency_matrix = torch.clamp(adjacency_matrix, min=0, max=1)\n",
    "\n",
    "    averaged_history = torch.zeros(num_agents, num_arms, device=device, requires_grad=True)\n",
    "\n",
    "    for run in range(0, averaging_runs):\n",
    "\n",
    "        history = torch.zeros(2, num_agents, num_arms, device=device, requires_grad=True)\n",
    "    \n",
    "        for epoch in range(1, max_epochs):\n",
    "            performance_estimate = history.sum(dim=0) / (history.sum(dim=0).sum(dim=1).unsqueeze(1) + 1) + epsilon * torch.sqrt(np.log(epoch)/(1+history.bool().sum(dim=0).int()))\n",
    "            choice = torch.argmax(performance_estimate + influence_weight * adjacency_matrix @ performance_estimate, dim=1)\n",
    "            \n",
    "            rewards = torch.normal(mean=arm_performance[choice, 0], std=torch.abs(arm_performance[choice, 1]))\n",
    "\n",
    "\n",
    "            current_history  = torch.zeros(num_agents, num_arms, device=device)\n",
    "\n",
    "            for i in range(num_agents):\n",
    "                for j in range(num_arms):\n",
    "                    if j == choice[i]:\n",
    "                        current_history[i, j] = rewards[i]\n",
    "\n",
    "\n",
    "            history = torch.cat((history, current_history.unsqueeze(0)), dim=0)\n",
    "\n",
    "        history = history.bool().sum(dim=0).float() / history.bool().sum(dim=0).float().max()\n",
    "\n",
    "        averaged_history = averaged_history + history\n",
    "        \n",
    "    averaged_history = averaged_history / averaging_runs\n",
    "    \n",
    "  \n",
    " \n",
    "\n",
    "    #Frobenius norm\n",
    "    loss = torch.norm(averaged_history - average_history_true, p='fro')\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {train_epoch} Loss: {loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6888, 0.2940, 0.2669, 0.7875, 0.2519],\n",
       "        [0.6291, 0.5302, 0.3250, 0.6518, 0.6863],\n",
       "        [0.4272, 0.0538, 0.5969, 0.1319, 0.4401],\n",
       "        [0.1027, 0.8306, 0.1849, 0.3191, 0.6685],\n",
       "        [0.6106, 0.2331, 0.1795, 0.8182, 0.6294]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_matrix = torch.rand(num_agents, num_agents, device=device, requires_grad=True)\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8293, 0.3539, 0.3214, 0.9480, 0.3032],\n",
       "        [0.7574, 0.6383, 0.3913, 0.7847, 0.8262],\n",
       "        [0.5143, 0.0648, 0.7186, 0.1588, 0.5298],\n",
       "        [0.1237, 1.0000, 0.2227, 0.3842, 0.8048],\n",
       "        [0.7351, 0.2806, 0.2161, 0.9850, 0.7577]], device='cuda:0',\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjacency matrix / max element \n",
    "adjacency_matrix = adjacency_matrix / adjacency_matrix.max()\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sigmoid(): argument 'input' (position 1) must be Tensor, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49msigmoid(\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m0.9458\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: sigmoid(): argument 'input' (position 1) must be Tensor, not float"
     ]
    }
   ],
   "source": [
    "torch.sigmoid(2 * 0.9458 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = torch.zeros(2, num_agents, num_arms, device=device, requires_grad=True)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6651, 1.6651, 1.6651, 1.6651, 1.6651],\n",
       "        [1.6651, 1.6651, 1.6651, 1.6651, 1.6651]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_estimate = history.sum(dim=0) / (history.sum(dim=0).sum(dim=1).unsqueeze(1) + 1) + epsilon * torch.sqrt(np.log(epoch)/(1+history.bool().sum(dim=0).int()))\n",
    "performance_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
